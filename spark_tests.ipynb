{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark # check if pyspark is installed\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Window, Row\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "dataset_folder = os.path.join(current_directory, 'datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.find()\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/18 11:59:53 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.188 instead (on interface wlp3s0)\n",
      "22/02/18 11:59:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/otheos/github/pyspark_nltk/venv/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/18 11:59:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"practiseSession\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[You can find more options in the docs](https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(filename):\n",
    "    df = spark.read.format('csv').options(header='true').options(infer_schema='true').load(filename)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_movies_df = load_dataframe(os.path.join(dataset_folder, 'movies.csv'))\n",
    "raw_links_df = load_dataframe(os.path.join(dataset_folder, 'links.csv'))\n",
    "raw_ratings_df = load_dataframe(os.path.join(dataset_folder, 'ratings.csv'))\n",
    "raw_tags_df = load_dataframe(os.path.join(dataset_folder, 'tags.csv'))\n",
    "raw_genome_tags_df = load_dataframe(os.path.join(dataset_folder, 'genome-tags.csv'))\n",
    "raw_genome_scores_df = load_dataframe(os.path.join(dataset_folder, 'genome-scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_movies_df.show(10, truncate=False, vertical=False) # | movieId | title  | genres |\n",
    "# TODO: Release date of movies are in `title` column, lets take it out later\n",
    "raw_links_df.show(10, truncate=False, vertical=False) # | movieId | imdbId | tmdbId |\n",
    "raw_ratings_df.show(10, truncate=False, vertical=False) #| userId | movieId | rating | timestamp |\n",
    "raw_tags_df.show(10, truncate=False, vertical=False) # | userId | movieId | tag | timestamp |\n",
    "raw_genome_tags_df.show(10, truncate=False, vertical=False) # | tagId | tag |\n",
    "raw_genome_scores_df.show(10, truncate=False, vertical=False) # | movieId | tagId | relevance |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing `released_year` column and adding to `raw_movies_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_movies_df = raw_movies_df.withColumn(\n",
    "    'release_year', \n",
    "    regexp_extract('title', r'\\(([^)]*)\\)', 1)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------+-------------------------------------------+----+\n",
      "|movieId|title                             |genres                                     |year|\n",
      "+-------+----------------------------------+-------------------------------------------+----+\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|1995|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |1995|\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |1995|\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |1995|\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |1995|\n",
      "|6      |Heat (1995)                       |Action|Crime|Thriller                      |1995|\n",
      "|7      |Sabrina (1995)                    |Comedy|Romance                             |1995|\n",
      "|8      |Tom and Huck (1995)               |Adventure|Children                         |1995|\n",
      "|9      |Sudden Death (1995)               |Action                                     |1995|\n",
      "|10     |GoldenEye (1995)                  |Action|Adventure|Thriller                  |1995|\n",
      "+-------+----------------------------------+-------------------------------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_movies_df.show(10, truncate=False, vertical=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e0ba01defd48b6e7ffe5f7f300dbfb14d21b0c2e0b0feda974f330036a5ddc46"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
